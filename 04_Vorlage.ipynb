{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schahor/TU_25_SS_Data-Mining-und-Maschinelles-Lernen-2025/blob/main/04_Vorlage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEHFUTHoheSd"
      },
      "outputs": [],
      "source": [
        "# Importieren der benötigten Libraries\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import tree\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Aufgabe 4.2 Entscheidungsbäume für Klassifikation\n"
      ],
      "metadata": {
        "id": "EjG3UMGOiRHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[sklearn.tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) ist eine Klasse, die eine Mehrklassenklassifizierung eines Datensatzes durchführen kann.\n",
        "\n",
        "Wie bei anderen Klassifikatoren nimmt _DecisionTreeClassifier_ zwei Arrays während des Trainings als Eingabe entgegen: ein Array _X_, _sparse_ oder _non-sparse_, mit der Größe _[n\\_samples, n\\_features]_, das die Trainingsproben enthält, und ein Array _Y_ mit ganzzahligen Werten, mit der Größe _[n\\_samples]_, das die Klassenbezeichnungen für die Trainingsproben enthält.\n"
      ],
      "metadata": {
        "id": "R176R6CeCudk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and investigate the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7ykmPtzr3TX",
        "outputId": "e436a5e4-6351-4927-e467-ff19dfc5e938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4) (150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a Decision tree on the iris data\n",
        "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
        "clf = clf.fit(X, y)"
      ],
      "metadata": {
        "id": "g4WZ3sHYsbkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the tree for investigation\n",
        "plt.figure(figsize=(14,12))\n",
        "_ = sklearn.tree.plot_tree(clf, fontsize=9, feature_names=iris.feature_names, class_names=iris.target_names)"
      ],
      "metadata": {
        "id": "C9gX4DxPuAGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a) Unsichere Vorhersagen\n",
        "\n",
        "Entscheidungsbäume erlauben es eine (Pseudo)-Wahrscheinlichkeit für die Entscheidungen anzugeben.\n",
        "Finden Sie alle Entscheidungen des Modells für den Testdatensatz, für welches das Modell keine 100\\,\\% Zuordnung treffen konnte.\n",
        "Verwenden Sie dabei die Methode _clf.predict\\_proba_.\n",
        "\n",
        "Wir verwenden hierzu den bekannten [Iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)-Datensatz. Ziel ist die Klassifizierung von Untergruppen der [Schwertlilie](https://de.wikipedia.org/wiki/Schwertlilien) (Iris) anhand der Merkmale _petal_ (Blütenblatt) und _sepal_ (Kelchblatt) Länge."
      ],
      "metadata": {
        "id": "I080iO67r9xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train another model with a train-test split and a max depth of 3\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "3g5SoaT2vie8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the new tree for investigation\n"
      ],
      "metadata": {
        "id": "OitoyXOzwfMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Computes a boolean array where all items with a probability != 1 are marked as true\"\"\"\n"
      ],
      "metadata": {
        "id": "PfZJsEr0vLJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b) Entscheidungsregionen\n",
        "\n",
        "Um die Entscheidungsregionen zu visualisieren, können wir eine Vorhersage für jeden möglichen Datenpunkt um die gültige Region um den Iris-Datensatz machen. Zur Erleichterung der Visualisierung verwenden wir nun nur noch die ersten 2 Features des Iris-Datensatzes für das Training.\n",
        "\n",
        "Visualisieren Sie die Entscheidungsregionen des trainierten Modells dar. Sie können hierzu [sklearn.inspection.DecisionBoundaryDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.DecisionBoundaryDisplay.html#sklearn.inspection.DecisionBoundaryDisplay.from_estimator) verwenden. Unterscheiden Sie dabei visuell die Trainings- und Testmenge"
      ],
      "metadata": {
        "id": "-X6kGICAyZ1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train decision tree\n",
        "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
        "X = iris.data[:, :2]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
        "clf = clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "yXlsCx-nt3Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the decision boundaries"
      ],
      "metadata": {
        "id": "T4BrUfjf04xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c) Kreuzvalidierung\n",
        "\n",
        "Wir können visuell erkennen, dass der Entscheidungsbaum mit zunehmender Tiefe dazu neigt, sich zu spezialisieren, um zu den einzelnen Datenpunkten zu passen, was zu komplexeren Entscheidungsregionen führt.\n",
        "Um den optimalen Wert für die maximale Tiefe zu finden, können wir außerdem eine Kreuzvalidierung des 2D-Iris-Datensatzes über einen Bereich möglicher Werte für den Parameter für die maximale Tiefe durchführen.\n",
        "\n",
        "Implementieren Sie die Methode _get\\_acc\\_per\\_depth_, welche eine 10-fache Kreuzvalidierung durchführt und die korrespondierenden Train- und Testgenauigkeiten zurückgibt.\n"
      ],
      "metadata": {
        "id": "8OSy_2ts62ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_acc_per_max_depth(X: np.ndarray, y: np.ndarray, max_depths: range) -> [np.ndarray, np.ndarray]:\n",
        "    \"\"\"Runs 10-fold cross validation for all given depths and\n",
        "     returns an array for the corresponding train and test accuracy\"\"\""
      ],
      "metadata": {
        "id": "_G-goRPa5-Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(acc_test, acc_train, depths_to_eval):\n",
        "    # Plot results\n",
        "    plt.figure()\n",
        "    plt.scatter(depths_to_eval, acc_test, label=\"Accuracy Test\", marker=\"^\")\n",
        "    plt.scatter(depths_to_eval, acc_train, label=\"Accuracy Train\", marker=\"x\")\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Maximum Tree Depth\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Decision Tree: Accuracy vs. Max. Depth\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "efJhQmn170ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_train, acc_test = get_acc_per_max_depth(iris.data, iris.target, range(1,16))"
      ],
      "metadata": {
        "id": "xtNYTeK07FaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aufgabe 4.3 Entscheidungsbäume für Regression"
      ],
      "metadata": {
        "id": "_5sxxRD78YPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entscheidungsbäume können auch zur Regression verwendet werden.\n",
        "Dazu erstellen wir eine verrauschte Sinusfunktion.\n",
        "Wir können jetzt Entscheidungsbäume anpassen, um die Sinusfunktion zu erlernen. Als Ergebnis werden lokale lineare Regressionen gelernt, die sich der Sinuskurve annähern."
      ],
      "metadata": {
        "id": "ItkN_Zo_8cy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def distorted_sin():\n",
        "    # Create a random dataset\n",
        "    X_cont = np.sort(10 * np.random.rand(80, 1), axis=0)\n",
        "    y_cont = np.sin(X_cont).ravel()\n",
        "    y_cont += 0.5 * (0.5 - np.random.rand(80))\n",
        "    y_cont[::5] += 3 * (0.5 - np.random.rand(16))\n",
        "    return X_cont, y_cont"
      ],
      "metadata": {
        "id": "2gopg_L28Ra5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "X, y = distorted_sin()"
      ],
      "metadata": {
        "id": "fFsgYope89wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the training data\n",
        "plt.scatter(X, y)"
      ],
      "metadata": {
        "id": "98OeITXQ9Cl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a) Regression\n",
        "\n",
        "Verwenden Sie den [sklearn.tree.DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) in der Methode _get\\_dt\\_prediction_ um eine Regression mittels eines Entscheidungsbaum anzuwenden. Geben Sie anschließend die Vorhersagen des Modells für gegebenen Trainingdatensatz zurück.\n"
      ],
      "metadata": {
        "id": "_6BkrURT8lXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dt_prediction(X_train: np.ndarray, y_train: np.ndarray, max_depth: int) -> np.ndarray:\n",
        "    \"\"\"Fits a decision tree regressor and returns its predictions as an array.\"\"\""
      ],
      "metadata": {
        "id": "lKzVdIbv9O9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b) Ergebnisvisualisierung\n",
        "\n",
        "Wir können sehen, dass, wenn die maximale Tiefe des Baumes (gesteuert durch den Parameter _max\\_depth_ zu hoch eingestellt ist, die Entscheidungsbäume zu feine Details der Trainingsdaten lernen und aus dem Rauschen lernen, d.h. sie _überanpassen_ sich.\n",
        "\n",
        "Zeigen Sie die verschiedenen Anpassungen für die unterschiedlichen Einstellungen von _max\\_depth_ in der Methode _plot\\_regression\\_models_ an.\n"
      ],
      "metadata": {
        "id": "iyU8t2QoDy6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions for depth 2 and 5\n"
      ],
      "metadata": {
        "id": "aSAl5TdA9csH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_regression_models(X_cont: np.ndarray, y_cont: np.ndarray, y_1: np.ndarray, y_2: np.ndarray):\n",
        "    \"\"\"Plots the regression results for y_1 and y_2 on top of the training data X_cont, y_cont.\"\"\"\n"
      ],
      "metadata": {
        "id": "5RrSpUGZ9xq9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}